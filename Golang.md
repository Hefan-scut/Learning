##### Channel特点

- 给一个nil的channel发送数据或接受数据，会造成永久阻塞
- 给已经关闭的channel发送数据，会引起panic
- 从一个已经关闭的channel接受数据，如果缓冲区中为空，则返回一个零值

##### Channel缓冲

```go
ch1 := make(chan int)
ch2 := make(chan int, 1)
```

- 无缓冲是同步的，ch1<-1向通道放1后必须要有别的协程接手这个参数，ch1<-1之后的代码才会继续执行下去，不然就会一致阻塞
- 有缓冲是异步的，ch2<-1不会阻塞，因为缓冲大小是1，只有当放第二个值的时候 第一个还没被人拿走，这时候才会阻塞
- 无缓冲：就是一个送信人去你家门口送信 ，你不在家 他不走，你一定要接下信，他才会走。无缓冲保证信能到你手上
- 有缓冲：就是一个送信人去你家仍到你家的信箱 转身就走 ，除非你的信箱满了，他必须等信箱空下来。

##### new的作用

```go
func new(Type) *Type
```

- new创建一个该类型的实例，并且返回指向该实例的指针
- 通常使用new函数来分配空间
- 传递给new函数的是一个类型，而不是一个值
- 返回值是指向这个新分配的地址的指针

##### make的作用

```go
func make(Type, size IntegerType) Type
```

- make的作用是初始化slice，map，chan，然后返回引用
- make(T, args)函数的目的和new(T)不同，仅仅用于创建slice，map，channnel，而且返回类型是实例

##### Printf(), Sprintf(), Fprintf()区别

- Printf：标准输出，一般是屏幕，也可以重定向
- Sprintf：把格式化字符串输出到指定的字符串
- Fprintf：把格式化字符串输出到文件

##### 数组和切片的区别

数组

- 固定长度，数组长度是数组类型的一部分，[3]int和[4]int是两种不同的数组类型
- 需要指定长度，不指定也会根据初始化，自动推算大小
- 大小不可改变
- 数据通过值传递

切片

- 可以改变长度，不需要指定大小
- 具有三个属性，指针，长度，容量
- 可以通过数组初始化，也可以通过make()来初始化
- 初始化的时候len=cap，然后进行扩容
- 切片通过地址传递(引用传递)，切片看起来像是引用传递，但其实是值传递

##### 切片的底层实现

- 基于数组实现，底层是数据，内存连续分配
- 对象非常小，只有3个字段的数据结构：指向底层数组的指针/切片长度/切片容量
- 扩容策略
  - 如果新申请容量大于2倍的旧容量，最终容量就是新申请的容量
  - 否则判断，如果旧切片的长度小于1024，则最终容量是旧容量的两倍
  - 否则判断，如果旧切片的长度大于等于1024，则最终容量从旧容量开始循环增加原来的1/4，直到最终容量大于等于新申请的容量
  - 如果最终容量溢出，则最终容量就是新申请容量
- 扩容前后
  - 原数据还有容量，扩容以后的数组还是指向原来的数组
  - 原数组无容量，默认先开一篇内存区域，把原来的值拷贝过来，再执行append()操作
  - 复制一个slice，最好使用copy()函数

##### 值传递和地址传递的区别

- 值传递只会把参数的值复制一份放进对应的函数，两个变量的地址不同，不可相互修改
- 地址传递(引用传递)会将变量本身传入对应的函数，在函数中可以对该变量进行值内容的修改
- **Go语言中所有的传参都是值传递，都是一个副本/拷贝**，因为拷贝的内容有时候是非引用类型(int, string, struct等)，这样就在函数中无法修改原内容；有的是引用类型(指针, map, slice, chan等这些)，这样就可以修改原内容

- 在传递数组或者内存占用非常大的结构体时，应该尽量使用指针作为参数类型来避免发生数据复制进而影响性能

##### defer

```go
defer func()
```

作用

- defer语句被执行，跟在defer后面的函数会被延期执行，直到包含该defer语句的函数执行完毕后，defer后的函数才会被执行，无论是正常结束还是panic导致的异常结束
- 可以在一个函数中执行多条defer语句，执行顺序与声明顺序相反

常用场景

- defer语句常被用于处理成对的操作，如打开、关闭、连接、断开连接、加锁、释放锁
- 通过defer机制，不论函数逻辑多复杂，都能保证在任何执行路径，资源被释放，释放资源的defer应该直接跟在请求资源的语句后

##### 接口

- Go语言的接口是一种内置类型，它定义了一组方法的签名
- 在Go语言中，实现接口不需要显示声明实现的接口(Java需要)，实现接口的所有方法就隐式地实现了接口
- 在接口中只能定义方法，不能包含成员变量(Java可以)

```go
Type error interface {
		Error() string
}
```

- Go语言中有两种略微不同的接口，一种是带有一组方法的接口，另一种是不带任何方法的interface{}，所有的参数类型都可以转换成interface{}类型，但interface{}类型**不是任意类型**，Print函数不接受任意类型的参数，只接受interface{}类型的值，在调用Print函数时会对参数v进行类型转换，将原来的Test类型转换成interface{}类型

```go
package main

func main() {
	type Test struct{}
	v := Test{}
	Print(v)
}

func Print(v interface{}) {
	Println(v)
}
```

-  查看接口类型的具体类型：c.(type)
- 以接口类型的某种具体身份调用：c.(*Cat).Quack()

##### 动态派发

- 动态派发是在运行期间选择具体多态操作（方法或者函数）执行的过程，它是面向对象育秧中的常见特性

- Go虽然不是严格意义上的面相对象语言，但接口的引入为它带来了动态派发的特性

- 调用接口类型的方法时，如果编译期间不能确认接口类型，Go语言会在运行期间决定具体调用该方法的哪个实现，如下所示

  ```
  func main() {
  	var c Duck = &Cat{Name: "draven"}
  	c.Quack()   // 以Duck接口类型的身份调用，需要经过运行时的动态派发
  	c.(*Cat).Quack()  // 以*Cat具体类型的身份调用，编译期就会确定调用的函数
  }
  ```

##### Mutex

状态

- mutexLocked - 表示互斥锁的锁定状态
- muteWoken - 表示从正常模式被唤醒
- muteStatving - 当前的互斥锁进入饥饿状态
- waitersCount = 当前互斥锁上等待的Goroutine个数

模式

- 正常模式
  - 当前的mutex只有一个goruntine来获取，那么没有竞争，直接返回。
  - 新的goruntine进来，如果当前mutex已经被获取了，则该goruntine进入一个先入先出的waiter队列，在mutex被释放后，waiter按照先进先出的方式获取锁。该goruntine会处于自旋状态(不挂起，继续占有cpu)。
    - 自旋锁：等待的时候会占用CPU的互斥锁
  - 新的goruntine进来，mutex处于空闲状态，将参与竞争。新来的 goroutine 有先天的优势，它们正在 CPU 中运行，可能它们的数量还不少，所以，在高并发情况下，被唤醒的 waiter 可能比较悲剧地获取不到锁，这时，它会被插入到队列的前面。如果 waiter 获取不到锁的时间超过阈值 1 毫秒，那么，这个 Mutex 就进入到了饥饿模式。

- 饥饿模式

  - 在饥饿模式下，Mutex 的拥有者将直接把锁交给队列最前面的 waiter。新来的 goroutine 不会尝试获取锁，即使看起来锁没有被持有，它也不会去抢，也不会 spin(自旋)，它会乖乖地加入到等待队列的尾部。

  -  如果拥有 Mutex 的 waiter 发现下面两种情况的其中之一，它就会把这个 Mutex 转换成正常模式:

    - 此 waiter 已经是队列中的最后一个 waiter 了，没有其它的等待锁的 goroutine 了；

    - 此 waiter 的等待时间小于 1 毫秒。

##### Cond

Condition，Cond实现了一种条件变量，可以使用在多个Reader等待共享资源ready的场景

Broadcast和Signal的区别

- Broadcast会唤醒所有等待cond的goroutine
- Signal只唤醒1个等待cond的goroutine

Wait

- Wait()会自动释放c.L锁，并挂起调用者的goroutine，之后恢复执行

##### WaitGroup

用法

- main协程通过wg.Add(delta int)设置worker协程的个数，创建worker协程
- worker协程执行结束之后，都要调用wg.Done()
- main协程调用wg.Wait()且被block，知道所有协程全程执行结束后返回

实现原理

- waitgroup主要维护了2个计数器，一个是请求计数器，一个是等待计数器，两者组成一个64bit的值，请求计数器占高32bit，等待计数器占低32bit
- 每次Add执行，请求计算器v加1，Done方法执行，等待计算器减1，为0时通过信号量唤醒wait

##### Once

- Once可以用来执行且仅仅执行一次动作，常常用来初始化单例资源，比如并发访问只需初始化一次的共享资源，或者在测试的时候初始化一次测试资源
- Once只暴露了一个方法Do，可以多次调用Do方法，但是只有第一次调用时才会生效

##### CAS

- Compare And Swap，是一条原子指令，作用是让CPU先进行比较两个值是否相等，然后原子地更新某个位置的值
- CAS通过硬件实现，在硬件层面提升效率

##### Pool

- 频繁地分配、回收内存会给GC带来一定的负担
- sync.Pool可以将暂时不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配

##### Goroutine

Goroutine的切换管理不依赖于系统的线程和进程，也不依赖于CPU的核心数量，而是交给Golang的运行时统一调度

##### GM模型

- 调度器把G都分配到M上，不同的G在不同的M并发运行时，都需要向系统申请资源，比如堆栈内存等，因为资源是全局的，就会因为资源竞争造成很多损耗
- 为了解决这一问题，在运行时系统的时候加入P对象，让P去管理这个G对象，M想要运行G，必须绑定P，才能运行P所管理的G

##### GMP调度模型

G(Goroutine): 我们所说的协程，为用户级的轻量级线程，每个Goroutine对象中的sched保存着其上下文信息

M(Machine): 对内核级线程的封装，数量对应真实的CPU数（真正干活的对象）

P(Processor): 即为G和M的调度对象，用来调度G和M之间的关联关系，其数量可通过GOMAXPROCS()来设置，默认为核心数

![image-20220530211517710](/Users/fan.he/Library/Application Support/typora-user-images/image-20220530211517710.png)

- 每个P有个局部队列，局部队列保存待执行的goroutine(流程2)，当M绑定的P的局部队列已经满了之后就会把goroutine放在全局队列(流程2-1)
- 每个P和一个M绑定，M是真正的执行P中goroutine的实力(流程3)，M从绑定的P中的局部队列获取G来执行
- 当M绑定的P的局部队列为空时，M会从全局队列获取到本地度咧来执行G(流程3-1)，当从全局队列中没有获取到可执行的G时，M会从其他P的局部队列中偷取G来执行(流程3.2)，这种从其他P偷的方式称为work stealing
  - work stealing：获取P本地队列，当从本地队列上找不到可执行的g时，尝试从全局队列中拿，再拿不到的时候会从别的P里偷任务。P此时唤醒一个M，P继续执行其他的程序，M寻找是否有空闲的P，如果有则将该G移动到它本身。接下来M执行一个调度循环(调用G对象->执行->清理线程->继续找新的Goroutine执行)
- 当G因系统调用(syscall)阻塞时会阻塞M，此时P会和M解绑即hand off，并寻找新的idle的M，若没有idle的M就会新建一个M(流程5.1)
- 当G因channel或network I/O阻塞时，不会阻塞M，M会寻找其他runnable的G，当阻塞的G恢复后重新进入runnable进入P队列等待执行(流程5.3)

##### GC

三色标记原理

![image-20220530225844884](/Users/fan.he/Library/Application Support/typora-user-images/image-20220530225844884.png)



- 首先把所有的对象都放在白色的集合中
- 从跟节点开始遍历对象，遍历到的白色对象从白色集合中放到灰色集合中
- 遍历灰色集合中的对象，把灰色对象引用的白色集合对象放入到灰色集合中，同时把遍历过的灰色集合中的对象放到黑色的集合中
- 循环上述步骤，直到灰色集合中没有对象
- 上述步骤结束后，白色集合中的对象就是不可达对象，也就是垃圾，进行回收

写屏障

- Go在进行三色标记的时候并没有STW(stop to work)，也就是说，此时的对象还是可以进行修改的，考虑如下情况

![image-20220530230744598](/Users/fan.he/Library/Application Support/typora-user-images/image-20220530230744598.png)

- 我们在扫描灰色集合时，扫描到了对象A，并标记了对象A的所有引用，这时候，开始扫描对象D的引用，而此时，另一个goroutine修改了D->E的引用，变成了如下图

![image-20220530231013089](/Users/fan.he/Library/Application Support/typora-user-images/image-20220530231013089.png)

- 这样会导致E对象就扫描不到了，而被误以为白色对象，也就是垃圾，写屏障就是为了解决这样的问题

- 引入写屏障后，E会被认为是存活的，即使后面E被A对象抛弃，E会被下一轮的GC进行回收，这一轮GC是不会对对象E进行回收的

触发时机

- 主动触发：调用 runtime.GC
- 被动触发
  - 使用系统监控，该触发条件由runtime.forcegcperiod变量控制，默认为2分钟，当超过两分钟没有产生任何GC时，强制触发GC
  - 使用步调(Pacing)算法，其核心思想是控制内存增长的比例，如Go的GC是一种比例GC，下一次GC结束时候的堆大小和上一次GC存活堆大小成比例

##### Redis

概念：Redis是一个高性能的key-value数据库

特点

- 性能极高，读的速度是110000次/s，写的速度是81000次/s
  - 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘
  - 如果不将数据放在内存中，磁盘I/O速度会严重影响Redis的性能

- 支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用
  - 也可以运行在内存，在对不同数据集进行高速读写时需要权衡内存，数据量不能大于硬件内存
- 支持五种数据类型：string(字符串)，hash(哈希)，list(列表)，set(集合)及zset(有序集合)
- 支持数据备份，即master-slave模式的数据备份
- 支持原子性和事务性
- 具有丰富特性，支持publish/subscribe，通知，key过期等特性

Redis是单进程单线程的，redis利用队列计数将并发访问变为串行访问

字符串类型的值最大容量：512M

持久化机制

- RDB(Redis Database)

  - 使用数据集快照的方法记录Redis数据库的所有键值对，在某个时间点写入一个临时文件，持久化结束后，用这个临时文件替换上次持久化的文件，达到数据恢复
  - 优点
    - 只有一个dump.rdb文件，方便持久化
    - 容灾性好，一个文件可以保存到安全的磁盘
    - 性能最大化，fork子进程来完成写操作，让主进程继续处理命令。使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了Redis的高性能
    - 相对于数据集大时，比AOF的启动效率更高
  - 缺点
    - 数据安全性低，RDB是间隔一段时间进行持久化，如果持久化之间Redis发生故障，会发生数据丢失，所以这种方式更适合数据要求不严谨的时候

- AOF(Append only file)

  - 所有的命令行记录以redis命令请求的格式保存在AOF文件

  - 优点

    - 数据安全，aof持久化可以配置appendfsync属性，可以设置为always，每进行一次命令操作就记录到aof文件中一次
    - 通过append模式写文件，即使中途服务器宕机，可以通过redis-check-aof工具解决数据一致性问题
    - rewrite机制，文件过大时会对命令进行合并充血，可以删除其中的某些命令

  - 缺点

    - AOF文件比RDB文件大，恢复速度慢
    - 数据集大的时候，比rdb启动效率低

- 常见性能问题和解决方案

  - Master不要写内存快照，如果master写内存快照，save命令调度rdbsave函数，会阻碍主线程的工作，当快照比较大时对性能影响非常大
  - 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次
  - 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网
  - 主从复制不要使用图状结构，用单向链表结构更为稳定，即Master->slave1->slave2->...，方便解决单点故障问题，实现slave对master的替换。如果master挂了，可以立即启动slave1做master

- Redis过期键的删除

  - 定时删除：在设置键的过期时间的同时，创建一个定时器timer，让定时器在键的过期时间来临时，立即执行对键的删除操作
  - 惰性删除：放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键，如果没有过期，就返回该键
  - 定期删除；每隔一段时间程序就对数据库进行一次检查，删除里面的过期键。

-  Redis的回收策略

  一个客户端运行了新的命令，添加了新的数据。Redis检查内存使用情况，如果大于maxmemory的限制，则根据设定好的策略进行回收，一个新的命令被执行。我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收到边界以下。如果达到设置的上限，Redis的写命令会返回错误信息，但是读命令还可以正常返回。

  - volatile-lru: 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
  - volatile-ttl: 从已设置过期时间的数据集中挑选将要过期的数据淘汰
  - volatile-random: 从已设置过期时间的数据集中任意选择数据淘汰
  - Allkey-lru: 从数据集中挑选最近最少使用的数据淘汰
  - Allkey-ttl: 从数据集中挑选将要过期的数据淘汰
  - Allkey-random: 从数据集中任意选择数据淘汰
  - No-enviction(驱逐) : 禁止驱逐数据

- Redis的同步机制

  - Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放

- 常用命令

  - 过期时间命令：EXPIRE
  - 永久有效命令：PERSIST
  - 获取指定key模式命令：Keys（有阻塞）
    - Redis是单线程的，keys指令会导致线程阻塞一段时间，线上服务会顶钝，直到指令执行完毕，服务才能回复

  - 获取指定key模式命令：scan（无阻塞）
    - scan模式可以无阻塞取出指定模式的key列表，但是会有一定的重复概率，可以在客户端做一次去重，整体所花费的时间会比直接用keys指定长


- Redis的内存优化
  - 尽可能使用散列表(hashes)，散列表(是说散列表里面存储的数少)使用的内存非常小，应该尽可能地将数据模型抽象到一个散列表里面。比如web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面

- 如果有大量的key过期时间设置过于集中，到过期的时间点，redis可能会出现短暂的卡顿现象，一般需要在时间上加个随机值，使得过期时间分散一些
- 缓存可能出现的问题
  - 数据雪崩
    - 缓存挂掉，所有请求全部达到DB，导致DB负荷大增，最终挂掉
    - 解决方案
      - 缓存高可用
      - 本地缓存
  - 数据穿透
    - 查询一个一定不存在的数据，缓存是不命中时被动写，并且处于容错考虑，如果从DB查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到DB去查询，失去了缓存的意义。
    - 解决方案
      - 缓存空对象：当从DB查询数据为空，仍然可以将这个空结果进行缓存，具体的值需要使用特殊的标识，能和真正的数据区分开。另外，需要设置较短的过期时间，一般建议不超过5分钟。
      - 布隆过滤器：在缓存服务的基础上，构建布隆过滤器数据结构，在其中存储对应的key是否存在，如果存在，说明该key对应的值不为空
  - 缓存击穿
    - 指某个极度“热点”数据在某个时间点过期时，恰好在这个时间点对这个KEY有大量的并发请求过来，这些请求发现缓存过期一般都会从DB加载数据并回设到缓存，但是这个时候大并发的请求可能会瞬间把DB压垮
    - 区别
      - 缓存击穿的key是真实存在的，穿透是不存在的
      - 缓存雪崩时很多key都没了，击穿只是一个
    - 解决方案
      - 互斥锁：请求发现缓存不存在后，去查询DB前，使用分布式锁，保证有且只有一个线程去查询DB，并更新到缓存
      - 手动过期：缓存上不设置过期时间，功能上将过期时间存在key对应的value里
- 缓存预热
  - 在刚启动的缓存系统中，如果缓存中没有任何数据，仅依靠用户请求的方式重建数据，对数据库的压力巨大，最好的策略是启动时就把热点数据加载好。

##### MySQL

- 数据库的三大范式（不一定要遵从，很多情况下都不遵从）

  在设计数据库结构的时候，要尽量遵循三范式，如果不遵守，必须有足够的理由。比如性能，事实上我们经常会为了性能而妥协数据库的设计

  - 第一范式：每个列都不可以再拆分
  - 第二范式：在第一范式的基础上，非主键列完全依赖于主键，而不能是依赖于主键的一部分
  - 第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键

- Binlog录入格式

  - statement
    - 每一条会修改数据的SQL都会记录在Binlog中，不需要记录每一行的变化，减少了BinLlog日志量
    - 由于SQL的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之列的语句无法被记录复制
  - row
    - 记录每一行的改动，但由于很多操作会导致大量行的改动，因此日志量太大
  - mixed
    - 折中方案，普通操作使用statement记录，无法使用statement的时候使用row

- MyISAM和InnoDB区别

  - 锁粒度：InnoDB锁粒度为行锁，MyISAM的锁粒度为表锁，InnoDB比MyISAM支持更高的并发，锁的开销更大，但能解决脏读和不可重复读的问题，更容易发生死锁。
    - 脏写
      - 事务 A 和事务 B 同时在更新一条数据，事务 A 先把它更新为 A 值，事务 B 紧接着就把它更新为 B 值。
      - 此时事务 B 是后更新那行数据的值，所以此时那行数据的值是 B。而且此时事务 A 更新之后会记录一条 undo log 日志。因为事务 A 是先更新的，它在更新之前，这行数据的值为 `NULL`。
      - 那么此时事务 B 更新完数据的值为 B，此时事务 A 突然回滚了，就会用它的 undo log 日志去回滚。此时事务 A 一回滚，直接就会把那行数据的值更新回 NULL 值。
    - 脏读：事务B查询了事务A修改过的数据，但此时事务A还没提交，所以事务A随时会回滚导致事务B再次查询就读不到事务A修改的数据了
    - 不可重复读
      - 假设缓存页里一条数据原来的值是 A 值，此时事务 A 开启之后，第一次查询这条数据，读取到的就是 A 值
      - 接着事务 B 更新了那行数据的值为 B 值，同时事务 B 立马提交了，然后事务 A 此时还没提交。大家注意，此时事务 A 是没提交的，它在事务执行期间第二次查询数据，此时查到的是事务 B 修改过的值，B 值，因为事务 B 已经提交了，所以事务 A 是可以读到的
      - 紧接着事务 C 再次更新数据为 C 值，并且提交事务了，此时事务 A 在还没提交的情况下，第三次查询数据，查到的值为 C 值
    - 幻读
      - 一个事务 A，先发送一条 SQL 语句，里面有一个条件，要查询一批数据出来，如 `SELECT * FROM table WHERE id > 10`。然后呢，它一开始查询出来了 10 条数据。接着这个时候，别的事务 B往表里插了几条数据，而且事务 B 还提交了，此时多了几行数据。
      - 于是事务 A 开始怀疑自己的眼镜了，为什么一模一样的 SQL 语句，第一次查询是 10 条数据，第二次查询是 12 条数据？难道刚才出现幻觉了？这就是「幻读」这个名词的由来
  - 可恢复性：InnoDB有事务日志，数据库崩溃后可以根据日志文件进行恢复，而MyISAM则没有事务日志
  - 查询性能
    - MyISAM要优于InnoDB
    - InnoDB在查询过程需要维护数据缓存，并且先定位到行所在的数据块，然后在从数据块中定位到要查找的行
    - MyISAM可以直接定位到数据所在的内存地址，直接找到数据
  - MyISAM缺点
    - 不支持事务操作
    - 不支持外键操作

- 索引

  - InnoDB是聚簇索引，MyISAM是非聚簇索引
    - 聚簇索引的顺序就是数据的物理存储顺序，而对非聚簇索引的索引顺序与数据物理排列顺序无关
    - 聚簇索引的叶节点就是数据节点。非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块
  - 优点
    - 大大加快数组的检索速度
  - 缺点
    - 创建和维护索引需要耗费时间，会降低增/删/改的执行效率
    - 索引需要占用物理空间
  - 类型
    - 主键索引：数据列不允许重复，不允许为NULL，一个表只能有一个主键
    - 唯一索引：数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引
      - 可以通过ALTER TABLE table_name ADD UNIQUE (column)创建唯一索引
      - 可以通过ALTER TABLE table_name ADD UNIQUE（column1, column2）创建唯一组合索引
    - 普通索引：基本的索引类型，没有唯一性限制，允许为NULL值
      - 可以通过ALTER TABLE table_name ADD INDEX index_name(column) 创建普通索引
    - 全文索引：适用于搜索引擎
      - 可以通过ALTER TABLE table_name ADD FULLTEXT (column) 创建全文索引

- InnoDB的四种事务隔离级别

  - read uncommitted: 读到未提交数据
  - read committed：解决脏读，存在不可重复读的问题
  - repeatable read：解决可重复读的问题
  - serializable: 串行事务

- char和varchar

  - char列和varchar类型在存储和检索方面有所不同
  - char列长度固定为创建表时声明的长度，长度值范围是1到255
  - 当char值被存储时，它们被用空格填充到特定长度，检索char值时需删除尾随空格

- 主键和候选键

  - 表格的每一行都由主键唯一标识，一个表只有一个主键
  - 主键也是候选键，按照惯例，候选键可以被指定为主键，并且可以用于任何外键引用

- 临时表

  - MySQL在执行SQL语句的过程中，通常会临时创建一些存储中间结果集的表，临时表只对当前连接可见，在连接关闭时，临时表会被删除并释放所有表的空间
  - MySQL会在以下几种情况产生临时表
    - UNION查询
    - FROM中的子查询

- SQL优化

  - 查询语句无论是使用哪种判断条件，等于/小于/大于，where左侧的条件查询极端不要使用函数或表达式
  - 使用explain命令优化select查询
  - 当只需要使用一条记录时，使用LIMIT 1
  - 不要直接使用SELECT * ， 而应该使用具体需要查询的表字段
  - 避免在WHERE字段使用NULL/!或>操作符
  - 使用Between and 替代IN
  - 为搜索字段创建索引
  - 使用LIKE%abc%不会走索引，而使用LIKE abc%会走索引
  - 对于枚举类型的字段，建议使用ENUM而不是VARCHAR，如性别、星期、类型、类别
  - 字段设计尽可能使用NOT NULL

- Union和union all

  - 通过union连接的SQL分别单独取出的列数必须相同
  - 使用union时，多个相等的行将会被合并，由于合并比较耗时，一般不直接使用union进行合并，而是通过采用union all合并

##### 网络和操作系统

- 进程和线程的区别
  - 进程是资源管理的基本单位，线程是程序执行的基本单位
  - 线程不拥有系统资源，都是可以访问隶属于进程的资源
  - 创建或撤销进程时，系统都要为之分配或回收系统资源，如内存空间，I/O设备等，OS所付出的开销显著大于在创建或者撤销线程时的开销
- 协程和线程的区别
  - 一个线程可以有多个协程，一个进程也可以有多个协程，但在同一时间其实只有一个协程拥有运行权
- 并发和并行的区别
  - 并发就是在一段时间内，多个任务都会被处理，但在某一时刻，只有一个任务在执行。单核处理器可以做到并发。比如有两个进程A和B，A运行一个时间片之后，切换到B，B运行一个时间片之后又切换到A。因为切换速度足够快，所以宏观上表现为在一段时间内能同时运行多个程序
  - 并行就是在同一时刻，有多个任务在执行，这个需要多核处理器才能完成，在微观上就能同时执行多条指令，不同的程序被放到不同的处理器上运行，这个是物理上的多个进程同时进行
- 进程间通讯
  - 管道
    - 匿名管道：只能单向流通，只能在具有亲缘关系（父子进程）的进程间使用
    - 命名管道：可以实现本机任意两个进程通信
  - 信号：可以在任何时候发给某一进程，而无需知道该进程的状态
    - LINUX常用信号
      - SIGHUP：用户从终端注销，所有已启动进程都将收到该进程
      - SIGINT：程序终止信号，程序运行过程中，按Ctrl+C键将产生该信号
      - SIGQUIT：程序退出信号，按ctrl+\\键将产生该信号
      - SIGKILL：用户终止进程执行信号，shell下执行kill -9
      - SIGTERM：结束进程信号，shell下执行kill 进程pid发送该信号
  - 信号量
    - 计数器，可以用来控制多个进程对共享资源的访问
    - 常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也在访问该资源
  - 消息队列
    - 有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。
    - 消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等特别
  - 共享内存
    - 映射一段能被其他进程所访问的内存，这段内存由一个进程创建，但多个进程都可以访问
    - 共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设计的
    - 往往与其他通信机制，如信号量配合使用
  - Socket，用于不同机器间的进程通信
- 线程间同步
  - 临界区：每个进程中访问临界资源的那段程序称为临界区，一次仅允许一个进程使用的资源称为临街资源。通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问
    - 优点：保证在某一时刻只有一个线程能访问数据的简便方法
    - 缺点
      - 虽然临界区同步速度很快，但却只能用来同步本进程内的线程
      - 只有临界区才不能跨进程，其他都可以
  - 互斥量：为协调共同对一个共享资源的单独访问而设计的，互斥量和临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限
    - 优点：可以跨进程
    - 缺点
      - 创建互斥量需要的资源更多
      - 互斥对象只有一个
  - 信号量：为控制具有有限数量用户资源而设计，是特殊的互斥量，当最大资源数=1时为互斥量
    - 优点
      - 适用于对Socket程序中线程的同步
      - 互斥对象可以有很多歌
    - 缺点
      - 必须有公共内存，不能用于分布式操作系统
  - 事件：用来通知线程有一些事情已发生，从而启动后继任务的开始
    - 优点
      - 可以实现不同进程中的线程同步操作
      - 允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务
- 死锁
  - 概念：在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其他进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁
  - 四个必要条件
    - 互斥：一个资源一次只能被一个进程使用
    - 请求与保持：一个进程因请求资源阻塞时，不释放现在拥有的资源
    - 不剥夺：进程获得的资源，在未完全使用之前，不能强行剥夺
    - 循环等待：若干进程之间形成一种头尾相接的环形等待资源关系
  - 如何处理死锁
    - 忽略该问题
    - 检查死锁并且恢复
    - 仔细对资源进行动态分配，以避免死锁
    - 通过破除死锁四个必要条件之一，来防止死锁产生
- 分页和分段
  - 分页
    - 把内存空间划分为大小相等且固定的块，作为主存的基本单位。因为程序数据存储在不同的页面，而页面又离散的分布在内存中，因此需要一个页表来记录映射关系，一实现从页号到物理块号的映射
    - 访问分页系统中内存数据需要两次的内存访问
      - 第一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址
      - 第二次是根据第一次得到的物理地址访问内存取出数据
  - 分段
    - 分页是为了提高内存利用率，分段是为了满足程序员在编写代码的时候的一些逻辑需求
    - 分段内存管理中，地址是二维的，一维是段号，二维是段内地址，其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的。
    - 由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应就是段表机制
  - 区别
    - 分页对程序员是透明的，分段需要程序员显示划分每个段
    - 分页的地址空间是一维地址空间，分段是二维的
    - 页的大小不可变，段的大小可以动态改变
    - 分页主要用于实现虚拟内存，从而获得更大的地址空间。分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护
- 交换空间
  - 操作系统把物理内存分为一块一块的小内存，每一块内存被称为页。当内存资源不足时，Linux把某些页的内容转移至硬盘上的一块空间上，以释放内存空间。
  - 硬盘上的那块空间叫做交换空间，这一过程称为交换。
  - 物理内存和交换空间的总容量就是虚拟内存的可用容量。
  - 一般交换不常用的页，程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去
- TCP
  - 三次握手
    - TCP报文中有两个非常重要的字段：序号字段和确认号字段。
    - 第一次握手：客户端向服务器发送SYN报文，并选取一个初始序列号(client_num)放置在序号字段中发送给服务器
    - 第二次握手：服务器接受到SYN报文后，为该连接分配缓存和变量，并发送ACK报文，此时确认号字段填写client_num+1的值，并选取一个server_num存放到序号字段中
    - 第三次握手：客户端收到ACK报文后，最后向服务端发送ACK报文，在确认号字段上填写server_num+1的值，并且这个报文可以携带数据
    - 完成三次握手后，客户端和服务器之间就可以相互发送包含数据的报文了。如果不是三次握手，服务器不知道客户端是否接受到了自己的ACK报文段，从而无法建立连接，四次握手就显得很多余
  - 洪泛攻击
    - 概念：TCP三次握手的第一步中，客户端会向服务器发送SYN报文段，服务器接收到SYN报文段后会为该TCP分配缓存和变量，如果攻击者大量地往服务器发送SYN报文段，服务器的连接资源会被耗尽，导致无法继续服务
    - 解决策略
      - 当服务器接收到SYN报文段时，不直接为该TCP分配资源，而知识打开一个半开的套接字，接着使用SYN报文段的源ID、目的ID、端口号以及只有服务器自己知道的秘密函数生成cookie，并把cookie作为序列号响应给客户端。
      - 如果客户端是正常建立连接，将会返回一个确认字段cookie+1的ACK报文，接下来服务器会根据确认报文的原ID、目的ID、端口号以及秘密函数计算出一个结果，如果结果的值+1等于确认字段的值，则证明是刚刚请求连接的客户端，这时候才为该TCP分配资源，这样一来就不会为恶意攻击的SYN报文段分配资源空间，避免的攻击
  - 四次挥手
    - 第一次，客户端向服务器发送FIN报文
    - 第二次，服务器向客户端发送ACK报文
    - 第三次，服务器向客户端发送FIN报文
    - 第四次，客户端向服务器发送ACK报文
    - 四次挥手后，服务端立即断开连接，客户端等待一段时间后断开连接(TIME_WAIT状态)
      - 客户端最后向服务器发送ACK报文是有可能丢失的，当出现超时，服务端会再次发送FIN报文段，如果客户端已经关闭了就收不到了，因此需要TIME_WAIT状态
    - TCP协议是全双工的，客户端和服务器都可以发起断开连接，两边各发起一次断开连接的深情，加上各自的两次确认，就像是执行了四次挥手

##### 消息队列

- kafka

  - 三个关键功能

    - 消息队列：发布和订阅消息流
    - 容错的持久方式存储记录消息流：Kafka会把消息持久化到磁盘，有效避免消息丢失的风险
    - 流式处理平台：在消息发布的时候进行处理，Kafka提供了一个完整的流式处理类库

  - 两大应用场景

    - 消息队列：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据
    - 数据处理：构建实时的流数据处理程序来转换或处理数据流

  - Kafka优势

    - 极致的性能：大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息
    - 生态系统兼容性无可匹敌：Kafka与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域

  - 重要概念

    Kafka将生产者发布的消息发送到Topic(主题)中，需要这些消息的消费者可以订阅Topic。

    - Producer（生产者）：产生消息的一方
    - Consumer（消费者）：消费消息的一方
    - Broker（代理）：可以看作是一个独立的Kafka实例，多个Kafka Broker组成一个Kafka Cluster
    - Topic（主题）：Producer将消息发送到特定的主题，Consumer通过订阅特定的Topic来消费消息
    - Partition（分区）：Partition属于Topic的一部分，一个Topic可以有多个Partition，并且同一Topic下的Partition可以分布在不同的Broker上，也就表明一个Topic可以横跨多个Broker
      - Kafka为分区引入了多副本机制，分区中的多个副本有一个为leader，其他为follower。
      - 我们发送的消息会被发送到leader副本，然后follower副本从leader副本中拉取消息进行同步
      - 生产者和消费者只与leader副本交互，其他副本只是leader副本的拷贝，只是为了保证消息存储的安全性
      - 当leader副本发生故障时会从follower中选举出一个leader，但是follower中如果有leader同步程度达不到要求的参加不了leader的竞选

  - 多副本机制和多分区机制的好处

    - 多分区：一个topic被分为多个分区，每个分区都可以处理生产者和消费者的信息
    - 多副本：每个分区有多个副本，只有leader可以处理生产者和消费者的信息![img](https://oscimg.oschina.net/oscnet/up-4b3cfe573c187eac43b664f898edde7c9b7.png)
    - 分区好处：Kafka通过给特定Topic指定多个Partition，而各个Partition可以分布在不同的Broker上，这样便能提供比较好的并发能力（负载均衡）
    - 副本好处：提高消息存储的安全性和容灾能力，不过也增加了所需要的存储空间

  - Zookeeper作用

    - Broker注册：在zookeeper上会有一个专门用来进行Broker服务器列表记录的节点。每个Broker在启动时，都会到Zookeeper上进行注册，即到/brokers/ids下创建属于自己的节点。每个Broker就会将自己的IP地址和端口等信息记录到该节点中去
    - Topic注册：在Kafka中，同一个Topic的消息会被分成多个分区并将其分布在多个Broker上，这些分区信息及与Broker的对应关系也都是由Zookeeper在维护。比如我创建了一个名字为my-topic的主题并且有两个分区，对应到zookeeper中会创建这些文件夹：/brokers/topics/my-topic/Partitions/0、/brokers/topics/my-topic/Patitions/1
    - 负载均衡：Kafka通过给特定Topic指定多个Partition，而各个Partition可以分布在不同的Broker上，这样便能提供比较好的并发能力。对于同一个Topic的不同Partition，Kafka会尽力将这些Partition分布到不同的Broker服务器上。当生产者产生消息后也会尽量投递到不同Broker的Partition里面。在Consumer消费的时候，Zookeeper可以根据当前的Partition数量以及Consumer数量来实现动态负载均衡

  - 如何保证消息的消费顺序

    - 一个topic只对应一个partition
    - 发送消息时指定Partition

  - 如何判断一个节点是否还活着

    - 节点必须可以维护和ZooKeeper的连接，ZooKeeper通过心跳机制检查每个节点的连接
    - 如果节点是个follower，他必须能及时的同步leader的写操作，延时不能太久

  - 分组策略

    - 生产者决定数据产生到集群的哪个partition中，每一条消息都是以（key，value）格式，Key是由生产者发送数据传入，所以生产者（key）决定了数据产生的哪个Partition。

##### CAP理论

它指出对于一个分布式计算系统来说，不可能同时满足以下三点：

- Consistency（一致性）：数据在多个副本之间能够保持一致的特性（严格的一致性）
- Availability（可用性）：系统提供的服务必须一直处于可用的状态，每次请求都能获取到非错的响应（不保证获取的数据为最新数据）
- Partition tolerance（分区容错性）：分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障

这里指的是，在发生网络分区的时候，强一致性和可用性只能2选1。P是前提，决定了P之后才有C和A的选择，P是必须要实现的

##### BASE理论

- Basically Available（基本可用）、Soft-state（软状态）和Eventually Consistency（最终一致性），基于CAP演变。
  - 基本可用：指分布式系统在出现不可预知故障的时候，允许损失部分可用性，但绝不等于系统不可用
  - 软状态：允许系统中的数据存在中间状态，并认为该状态的存在不会影响系统的整体可用，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时
  - 最终一致：强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。
- BASE理论的核心思想是即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。
- 也就是牺牲数据的一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要保持系统整体“主要可用”
- 针对数据库领域，BASE思想的主要实现是对业务数据进行拆分，让不同的数据分布在不同的机器上，以提升系统的可用性，当前主要有以下两种做法
  - 按功能划分数据库
  - 分片















